"""
–û–±—É—á–µ–Ω–∏–µ ML –º–æ–¥–µ–ª–∏ –Ω–∞ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö Softclub + —Å–∏–Ω—Ç–µ—Ç–∏–∫–∞
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç 6 features 
"""
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score
import xgboost as xgb
import os

def train_model():
    print("=" * 80)
    print("üöÄ –û–ë–£–ß–ï–ù–ò–ï ML –ú–û–î–ï–õ–ò –ù–ê –†–ï–ê–õ–¨–ù–´–• + –°–ò–ù–¢–ï–¢–ò–ß–ï–°–ö–ò–• –î–ê–ù–ù–´–•")
    print("=" * 80)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç
    print("\nüìä –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    df = pd.read_csv('data/training_data_balanced.csv')
    print(f"   ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
    print(f"\nüìà –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤:")
    print(f"   churned=0 (–∞–∫—Ç–∏–≤–Ω—ã–µ): {(df['churned'] == 0).sum()} ({(df['churned'] == 0).sum()/len(df)*100:.1f}%)")
    print(f"   churned=1 (–æ—Ç—á–∏—Å–ª–µ–Ω–Ω—ã–µ): {(df['churned'] == 1).sum()} ({(df['churned'] == 1).sum()/len(df)*100:.1f}%)")
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print("\nüîß –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    
    # 6 features (–ë–ï–ó payment_delays –∏ days_since_last_payment)
    feature_names = [
        'attendance_rate',
        'homework_completion',
        'test_avg_score',
        'communication_activity',
        'days_enrolled',
        'missed_classes_streak'
    ]
    
    X = df[feature_names].values
    y = df['churned'].values
    
    print(f"   Features: {len(feature_names)}")
    print(f"   Samples: {len(X)}")
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test (80/20)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    print(f"\nüìö –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö:")
    print(f"   Train: {len(X_train)} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤")
    print(f"   Test: {len(X_test)} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤")
    
    # –û–±—É—á–µ–Ω–∏–µ XGBoost
    print("\nüéì –û–±—É—á–µ–Ω–∏–µ XGBoost –º–æ–¥–µ–ª–∏...")
    
    model = xgb.XGBClassifier(
        max_depth=5,
        learning_rate=0.05,
        n_estimators=200,
        subsample=0.8,
        colsample_bytree=0.8,
        min_child_weight=3,
        gamma=0.1,
        reg_alpha=0.1,
        reg_lambda=1.0,
        random_state=42,
        eval_metric='logloss'
    )
    
    model.fit(
        X_train, y_train,
        eval_set=[(X_test, y_test)],
        verbose=False
    )
    
    print("   ‚úÖ –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞!")
    
    # –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
    print("\nüìä –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ:")
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1]
    
    # –ú–µ—Ç—Ä–∏–∫–∏
    accuracy = accuracy_score(y_test, y_pred)
    roc_auc = roc_auc_score(y_test, y_pred_proba)
    
    print(f"   Accuracy: {accuracy:.2%}")
    print(f"   ROC-AUC: {roc_auc:.2%}")
    
    print("\nüìã Classification Report:")
    print(classification_report(y_test, y_pred, target_names=['Active', 'Churned']))
    
    print("\nüî¢ Confusion Matrix:")
    cm = confusion_matrix(y_test, y_pred)
    print(f"   True Negatives (–ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∏ Active): {cm[0][0]}")
    print(f"   False Positives (–æ—à–∏–±–æ—á–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∏ Churned): {cm[0][1]}")
    print(f"   False Negatives (–ø—Ä–æ–ø—É—Å—Ç–∏–ª–∏ Churned): {cm[1][0]}")
    print(f"   True Positives (–ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∏ Churned): {cm[1][1]}")
    
    # Feature importance
    print("\nüéØ –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
    feature_importance = sorted(
        zip(feature_names, model.feature_importances_),
        key=lambda x: x[1],
        reverse=True
    )
    
    for feature, importance in feature_importance:
        bar = "‚ñà" * int(importance * 50)
        print(f"   {feature:25s} {importance:.3f} {bar}")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    print("\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
    os.makedirs('models/trained', exist_ok=True)
    model_path = 'models/trained/churn_model.json'
    model.save_model(model_path)
    print(f"   ‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_path}")
    
    print("\n" + "=" * 80)
    print("üéâ –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û –£–°–ü–ï–®–ù–û!")
    print("=" * 80)
    print(f"\nüìå –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –Ω–∞:")
    print(f"   - {len(df)} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ (—Ä–µ–∞–ª—å–Ω—ã–µ Softclub + —Å–∏–Ω—Ç–µ—Ç–∏–∫–∞)")
    print(f"   - 6 features (–±–µ–∑ payment features)")
    print(f"   - –ë–∞–ª–∞–Ω—Å: {(df['churned'] == 0).sum()/len(df)*100:.1f}% active vs {(df['churned'] == 1).sum()/len(df)*100:.1f}% churned")
    print(f"\nüìä –¢–æ—á–Ω–æ—Å—Ç—å: {accuracy:.2%}")
    print(f"üéØ ROC-AUC: {roc_auc:.2%}")


if __name__ == "__main__":
    train_model()
