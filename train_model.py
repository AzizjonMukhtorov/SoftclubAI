"""
üöÄ –û–ë–£–ß–ï–ù–ò–ï –° –§–û–ö–£–°–û–ú –ù–ê RECALL (–ü–û–õ–ù–û–¢–£)
–£–ª—É—á—à–∞–µ–º –º–æ–¥–µ–ª—å, —á—Ç–æ–±—ã –æ–Ω–∞ –Ω–∞—Ö–æ–¥–∏–ª–∞ –±–æ–ª—å—à–µ –æ—Ç—á–∏—Å–ª—è—é—â–∏—Ö—Å—è —Å—Ç—É–¥–µ–Ω—Ç–æ–≤.

–ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏:
1. Class Weights (scale_pos_weight) - –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤
2. Threshold Tuning - –ø–æ–¥–±–æ—Ä –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
"""
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve
import xgboost as xgb
import os

def train_high_recall_model():
    print("=" * 80)
    print("üöÄ –û–ë–£–ß–ï–ù–ò–ï HIGH-RECALL –ú–û–î–ï–õ–ò (–ß—Ç–æ–±—ã –Ω–µ –ø—Ä–æ–ø—É—Å–∫–∞—Ç—å –æ—Ç—á–∏—Å–ª–µ–Ω–∏—è)")
    print("=" * 80)
    
    # 1. –ó–∞–≥—Ä—É–∑–∫–∞
    print("\nüìä –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    df = pd.read_csv('data/softclub_training.csv')
    
    feature_names = [
        'attendance_rate',
        'homework_completion',
        'test_avg_score',
        'communication_activity',
        'days_enrolled',
        'missed_classes_streak'
    ]
    
    X = df[feature_names].values
    y = df['churned'].values
    
    # –†–∞—Å—á–µ—Ç –≤–µ—Å–∞ –¥–ª—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏
    # scale_pos_weight = (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ active) / (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ churned)
    n_active = (df['churned'] == 0).sum()
    n_churned = (df['churned'] == 1).sum()
    weight_ratio = n_active / n_churned
    
    print(f"   –ë–∞–ª–∞–Ω—Å: {n_active} active vs {n_churned} churned")
    print(f"   ‚öñÔ∏è  –í—ã—á–∏—Å–ª–µ–Ω scale_pos_weight = {weight_ratio:.2f}")
    
    # Split
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # 2. –û–±—É—á–µ–Ω–∏–µ —Å –≤–µ—Å–∞–º–∏
    print(f"\nüéì –û–±—É—á–µ–Ω–∏–µ XGBoost —Å –≤–µ—Å–æ–º –∫–ª–∞—Å—Å–∞ {weight_ratio:.2f}...")
    
    model = xgb.XGBClassifier(
        max_depth=4,            # –ß—É—Ç—å –º–µ–Ω—å—à–µ –≥–ª—É–±–∏–Ω–∞ –¥–ª—è –æ–±–æ–±—â–µ–Ω–∏—è
        learning_rate=0.03,     # –ú–µ–¥–ª–µ–Ω–Ω–µ–µ –æ–±—É—á–µ–Ω–∏–µ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
        n_estimators=300,
        scale_pos_weight=weight_ratio,  # üî• –ì–õ–ê–í–ù–û–ï –ò–ó–ú–ï–ù–ï–ù–ò–ï: –®—Ç—Ä–∞—Ñ—É–µ–º –∑–∞ –ø—Ä–æ–ø—É—Å–∫ churned
        subsample=0.8,
        colsample_bytree=0.8,
        gamma=0.2,
        random_state=42,
        eval_metric='logloss'
    )
    
    model.fit(X_train, y_train)
    print("   ‚úÖ –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞")
    
    # 3. –ü–æ–¥–±–æ—Ä –ø–æ—Ä–æ–≥–∞ (Threshold Tuning)
    print("\nüéöÔ∏è  –ü–æ–¥–±–æ—Ä –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞ (Threshold Tuning)...")
    
    y_pred_proba = model.predict_proba(X_test)[:, 1]
    
    # –ü–µ—Ä–µ–±–∏—Ä–∞–µ–º –ø–æ—Ä–æ–≥–∏
    best_threshold = 0.5
    best_f1 = 0
    best_recall = 0
    
    print(f"{'Threshold':<10} {'Recall':<10} {'Precision':<10} {'F1-Score':<10} {'Active':<10}")
    print("-" * 55)
    
    thresholds = np.arange(0.2, 0.7, 0.05)
    for t in thresholds:
        y_pred_t = (y_pred_proba >= t).astype(int)
        rec = recall_score(y_test, y_pred_t)
        prec = precision_score(y_test, y_pred_t)
        f1 = f1_score(y_test, y_pred_t)
        
        print(f"{t:.2f}       {rec:.2%}     {prec:.2%}      {f1:.2%}      ")
        
        # –ò—â–µ–º –ø–æ—Ä–æ–≥ —Å —Ö–æ—Ä–æ—à–∏–º Recall, –Ω–æ —á—Ç–æ–±—ã Precision –Ω–µ —É–ø–∞–ª –≤ –Ω–æ–ª—å (>50%)
        if f1 > best_f1 and prec > 0.5:
            best_f1 = f1
            best_threshold = t
            best_recall = rec

    print("-" * 55)
    print(f"üèÜ –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥: {best_threshold:.2f}")
    
    # 4. –ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ —Å –ª—É—á—à–∏–º –ø–æ—Ä–æ–≥–æ–º
    print(f"\nüìä –ò–¢–û–ì–û–í–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´ (Threshold = {best_threshold:.2f})")
    
    final_y_pred = (y_pred_proba >= best_threshold).astype(int)
    
    acc = accuracy_score(y_test, final_y_pred)
    rec = recall_score(y_test, final_y_pred)
    prec = precision_score(y_test, final_y_pred)
    f1 = f1_score(y_test, final_y_pred)
    roc = roc_auc_score(y_test, y_pred_proba)
    
    print(f"   Accuracy:  {acc:.2%}")
    print(f"   Precision: {prec:.2%}")
    print(f"   Recall:    {rec:.2%}  (üî• –ë—ã–ª–æ 52.71%)")
    print(f"   F1-Score:  {f1:.2%}")
    print(f"   ROC-AUC:   {roc:.2%}")
    
    cm = confusion_matrix(y_test, final_y_pred)
    print(f"\nüìã Confusion Matrix:")
    print(f"   [[TN={cm[0][0]}  FP={cm[0][1]}]")
    print(f"    [FN={cm[1][0]}   TP={cm[1][1]}]]")
    
    print(f"\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç: –ù–∞—à–ª–∏ {cm[1][1]} –∏–∑ {cm[1][0]+cm[1][1]} –æ—Ç—á–∏—Å–ª–µ–Ω–Ω—ã—Ö")
    print(f"   (–ü—Ä–æ–ø—É—Å—Ç–∏–ª–∏ —Ç–æ–ª—å–∫–æ {cm[1][0]})")
    
    # 5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    print("\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ HIGH-RECALL –º–æ–¥–µ–ª–∏...")
    os.makedirs('models/trained', exist_ok=True)
    model_path = 'models/trained/churn_model.json'
    model.get_booster().save_model(model_path)
    print(f"   ‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_path}")
    print("   –¢–µ–ø–µ—Ä—å –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –≤ API application!")

if __name__ == "__main__":
    train_high_recall_model()
